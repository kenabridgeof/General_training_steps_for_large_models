# 深度学习项目流程 (手机价格分类示例)

### 可调超参数

| 超参数               | 说明                          | 常用推荐值              |
| ----------------- | --------------------------- | ------------------ |
| `batch_size`      | 每次迭代处理的样本数，影响训练吞吐量与显存占用     | 16 / 32 / 64       |
| `learning_rate`   | 优化器初始学习率，控制参数更新步长           | 1e-2 / 1e-3 / 1e-4 |
| `optimizer`       | 优化算法类型，如 AdamW、SGD+Momentum | AdamW              |
| `epochs`          | 训练轮次总数                      | 50–200             |
| `train_val_split` | 训练/验证集划分比例或 K 折交叉验证         | 8:2 / 5 折交叉验证      |
| `seed`            | 随机种子，用于初始化数据分割和参数初始化        | 42                 |
| `hidden_dims`     | 隐藏层神经元规模列表，决定模型容量           | \[128, 64]         |
| `dropout_p`       | Dropout 丢弃率，用于抑制过拟合         | 0.1–0.5            |
| `weight_decay`    | 权重衰减系数（L2 正则化），防止过拟合        | 1e-5–1e-3          |

---

## 1. 数据加载与预处理

1. **数据读取 (Ingestion)**

   * 使用 `pandas.read_csv` 或定制化 ETL 管道，支持 CSV、Parquet、JSON、数据库等多种格式。

2. **类型转换 (Type Casting)**

   * 将 `DataFrame` 转为 NumPy，再利用 `torch.tensor` 转为浮点 (`float32`) 张量和整型 (`int64`) 标签。

3. **数据分割 (Data Splitting)**

   * 采用 `train_test_split` 或 `SubsetRandomSampler`，按 `train_val_split` 划分训练集与验证集；
   * 固定 `random_state` 以确保实验可复现。

4. **数据增强 (Augmentation)**

   * 可选：随机翻转、裁剪、归一化、标准化；
   * 调用 `torchvision.transforms` 或自定义预处理函数。

5. **封装数据集 (Dataset Wrapping)**

   * 使用 `TensorDataset` 或自定义 `Dataset` 类，将特征与标签打包；
   * 实现 `__len__`、`__getitem__` 方法，支持灵活扩展。

6. **小批量加载 (DataLoader)**

   * 构造 `DataLoader`，配置 `batch_size`、`shuffle`、`num_workers`、`pin_memory`、`drop_last` 等参数；
   * 支持高效并行预取和动态采样。

---

## 2. 模型定义 (Model Architecture)

1. **维度推断 (I/O Shape Inference)**

   * 根据数据集输出自动推断输入特征数和输出类别数。

2. **模块组合 (Module Composition)**

   * 可选组件：`nn.Linear`、`nn.Conv2d`、`TransformerEncoder`、`LSTM` 等；
   * 插入正则化层：`BatchNorm1d`、`LayerNorm`；
   * 添加激活函数：`ReLU`、`GELU`。

3. **参数初始化 (Weight Initialization)**

   * 使用 `xavier_uniform_`、`kaiming_normal_` 等策略，或加载预训练模型权重。

4. **设备分配 (Device Allocation)**

   * 调用 `model.to(device)`，支持单/多 GPU，或分布式训练 (`DDP`)。

---

## 3. 训练流程 (Training Loop)

1. **启用训练模式**

   * `model.train()`，确保 Dropout 生效，BatchNorm 更新统计量。

2. **损失函数 (Loss Function)**

   * 分类任务：`CrossEntropyLoss`；
   * 回归任务：`MSELoss`、`HuberLoss`。

3. **优化器配置**

   * `AdamW(model.parameters(), lr, weight_decay)`；
   * 或 `SGD(model.parameters(), lr, momentum=0.9, weight_decay)`。

4. **学习率调度**

   * 余弦退火 (`CosineAnnealingLR`)、阶梯衰减 (`StepLR`)、Warmup + 线性衰减等。

5. **梯度裁剪**

   * `clip_grad_norm_(model.parameters(), max_norm)` 防止梯度爆炸。

6. **主循环**

   * 遍历 `DataLoader` 批次：

     * 前向：`outputs = model(inputs)`
     * 计算损失：`loss = criterion(outputs, targets)`
     * 反向：`loss.backward()`
     * 更新：`optimizer.step()`，`optimizer.zero_grad()`
   * 记录并可视化损失、学习率等指标（TensorBoard/W\&B）。

7. **检查点保存**

   * 每 N 轮或验证指标提升时，`torch.save(model.state_dict(), "best.pth")`。

---

## 4. 验证与评估 (Validation & Metrics)

1. **启用评估模式**

   * `model.eval()` 并使用 `torch.no_grad()` 禁用梯度计算。

2. **指标计算 (Metrics)**

   * 准确率（Accuracy）、精确率/召回率/F1（Precision, Recall, F1）、AUC、BLEU、ROUGE 等。

3. **混淆矩阵**

   * 使用 `confusion_matrix` 分析错分模式。

4. **分类报告**

   * 调用 `classification_report` 输出各类详细指标。

5. **可视化**

   * 绘制 PR 曲线、ROC 曲线、样本预测对比图等。

---

## 5. 导出与部署 (Export & Deployment)

1. **模型序列化**

   * 保存 `state_dict` 或导出 TorchScript (`jit.trace`/`script`)。

2. **格式转换**

   * ONNX (`torch.onnx.export`)、TensorRT、OpenVINO 等。

3. **推理服务**

   * 封装 FastAPI/Flask 接口，支持批量在线推理。

4. **容器化部署**

   * 使用 Docker 构建镜像，集成依赖与配置。

5. **线上监控与迭代**

   * 日志采集、性能监控，自动触发微调或增量学习。
